ssh -i keypair_1.pem.txt ubuntu@ec2-18-221-54-110.us-east-2.compute.amazonaws.com


18.221.54.110:8080

spark://ip-172-31-20-241.us-east-2.compute.internal:7077

# start master
sudo ./spark-2.4.4-bin-hadoop2.7/sbin/start-master.sh

# start slave
sudo ./spark-2.4.4-bin-hadoop2.7/sbin/start-slave.sh spark://ip-172-31-20-241.us-east-2.compute.internal:7077

# open spark shell
sudo ./spark-2.4.4-bin-hadoop2.7/bin/pyspark

# stop slave
sudo ./spark-2.4.4-bin-hadoop2.7/sbin/stop-slave.sh spark://ip-172-31-20-241.us-east-2.compute.internal:7077

# stop master
sudo ./spark-2.4.4-bin-hadoop2.7/sbin/stop-master.sh


# unzip
wget http://apache.forsale.plus/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz

tar -xzvf spark-2.4.4-bin-hadoop2.7.tgz

# drop collection in mongodb
db.collection.drop()